<!DOCTYPE HTML>
<html lang="en-US">
<head>
	<title>AI 的語言世界：台大語言學研究所 謝舒凱</title>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=1274, user-scalable=no">
	<meta name="description" content="AI 的語言世界：台大語言學研究所 謝舒凱">
	<meta name="author" content="Shu-Kai Hsieh">
	<meta name="generator" content="slidify" />
	<!-- LOAD STYLE SHEETS -->
	<link rel="stylesheet" href="libraries/frameworks/shower/themes/ribbon/styles/screen.css">
	<link rel="stylesheet" media="print"
	  href="libraries/frameworks/shower/themes/ribbon/styles/print.css">
	<link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css">  <link rel="stylesheet" href = "libraries/widgets/quiz/css/demo.css">
<link rel="stylesheet" href = "libraries/widgets/interactive/css/aceeditor.css">
<link rel="stylesheet" href = "assets/css/ribbons.css">
<link rel="stylesheet" href = "assets/css/style-ribbon.css">

	<!--
		To apply styles to the certain slides
		use slide ID to get needed elements
		-->
	<style>
		#Cover h2 {
      margin:65px 0 0;
			color:#FFF;
			text-align:center;
			font-size:70px;
			}
		#FitToWidth h2,
		#FitToHeight h2 {
			color:#FFF;
			text-align:center;
			}
	</style> 
</head>
<body class="list">
  <header class="caption">
  	<h1>AI 的語言世界：台大語言學研究所 謝舒凱</h1>
	</header>
  <section class="slide cover" id="Cover">
  <div>
    <h2>AI: Semantics Network Batteries-included</h2>
    <p><img src="http://lopen.linguistics.ntu.edu.tw/static_cwm/img/lope.svg" alt="cover"></p>

<p><img src="logo.png" alt="cover"></p>

  </div>
</section>

<section class="slide " id="slide-2">
  <div>
    <h2>Outline</h2>
    <ol class = "build incremental">
<li><strong>AI, Deep Learning, and the (unknown) Future</strong></li>
<li>Cognition, Computation, Linguistics and AI : a (mis)match in Heaven?</li>
<li>Semantic Network: Representation, Memory and Processing</li>
<li>AI, AAI and AW (Artificial Wisdom)?</li>
</ol>

  </div>
</section>

<section class="slide " id="slide-3">
  <div>
    <h2>時代背景：我的 ** 不是人</h2>
    <p><img src="assets/img/jiajia.jpg" alt="Drawing" style="width: 400px;"/></p>

<blockquote>
<p>廚師、司機、醫師、健身教練、理專、律師、老師、情人(?)、。。。</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-4">
  <div>
    <h2>常被大眾談論（與誤解）的例子</h2>
    <ul>
<li>語音辨識 = 語言理解 </li>
<li>(語音辨識 + 字串關聯比對的) 聊天機器人 = AI</li>
<li>人形機器人(android/humanoid) = AI</li>
</ul>

  </div>
</section>

<section class="slide " id="slide-5">
  <div>
    <h2><code>ASIMO</code>, <code>Boston Dynamics</code>, up and coming</h2>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/kbaDdg4LA9k?start=435" frameborder="0" allowfullscreen></iframe>

  </div>
</section>

<section class="slide " id="slide-6">
  <div>
    <h2>恐怖谷理論 (uncanny valley)，準嗎？</h2>
    <blockquote>
<p>人類對機器人的好感度會隨著相似度增加，相似度高達 85% 時，會讓人心生恐懼與感到詭異。(森政弘,1970)</p>
</blockquote>

<iframe width="560" height="315" src="https://www.youtube.com/embed/3IFuv1AVouM" frameborder="0" allowfullscreen></iframe>

  </div>
</section>

<section class="slide " id="slide-7">
  <div>
    <h2>還是，<a href="https://panx.asia/archives/47499">可愛與需要打敗一切恐懼</a></h2>
    <p><img src="assets/img/uncanny.jpg" alt="Drawing" style="width: 500px;"/></p>

<p>(source: <a href="http://www.xenosystems.net/uncanny-valley/">http://www.xenosystems.net/uncanny-valley/</a>)</p>

  </div>
</section>

<section class="slide " id="slide-8">
  <div>
    <h2>語音辨識</h2>
    <p><a href="https://www.google.com/intl/en/chrome/demos/speech.html">Google Web Speech API Demonstration</a></p>

<blockquote>
<p>繼 <code>語音</code> 之後，<code>語意</code>（理解）是關鍵。</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-9">
  <div>
    <h2>其他的 AI 相關領域</h2>
    <ul>
<li><strong>知識搜尋處理</strong>  決策、推薦、預測、推理、、</li>
<li><strong>感知 (辨識)</strong>  視覺（人臉、圖形、物件）、語音與語言、情緒、、</li>
<li><strong>生成</strong>  圖文詩詞自動生成、語音與音樂合成、娛樂商務與療癒對話、、
<img src="assets/img/ma.jpg" alt="Drawing" style="width: 350px;"/>
<a href="https://www.slideshare.net/ckmarkohchang/neural-art-english-version">https://www.slideshare.net/ckmarkohchang/neural-art-english-version</a></li>
</ul>

  </div>
</section>

<section class="slide " id="slide-10">
  <div>
    <h2>其他參考</h2>
    <ul>
<li><a href="https://github.com/ckmarkoh/AcrosticPoem">藏頭詩</a></li>
<li><a href="http://www.deepbeat.org">歌詞/產生器</a> </li>
<li><a href="https://github.com/andersbll/neural_artistic_style">畫作</a></li>
<li><a href="">Predicting Future Human Behavior with Deep Learning (Vondrick, 2016)</a>
<img src="assets/img/dl.move.png" alt="Drawing" style="width: 350px;"/></li>
</ul>

  </div>
</section>

<section class="slide " id="slide-11">
  <div>
    <h2>Deep Learning and Language Technology</h2>
    <p><img src="assets/img/signLan.png" alt="Drawing" style="width: 500px;"/></p>

<p><code>Real Time American Sign Language Video Captioning using
Deep Neural Networks</code></p>

  </div>
</section>

<section class="slide " id="slide-12">
  <div>
    <h2>機器可以自學？<strong>可以!</strong></h2>
    <p><img src="assets/img/alphago.png" alt="Drawing" style="width: 540px;"/></p>

  </div>
</section>

<section class="slide " id="slide-13">
  <div>
    <h2>機器可以自學？<strong>可以嗎?</strong></h2>
    <ul>
<li>Elon Musk (Tesla) vs Mark Zuckerberg (FB)</li>
<li>Singularity: AI 的高鐵過站隱喻。</li>
</ul>

<blockquote>
<p>當萬物皆可量度，我們都也只是一堆感測器 (Hsieh, 2017)</p>
</blockquote>

  </div>
</section>

<section class="slide cover w" id="FitToWidth">
  <div>
    <h2>AI</h2>
    <p><img src="assets/img/ai.png" alt="Drawing" style="width: 850px;"/></p>

  </div>
</section>

<section class="slide " id="slide-15">
  <div>
    <h2>AI HERTORY: It all begins with ELIZA...</h2>
    <p><img src="assets/img/CEliza1.png" alt="Drawing" style="width: 500px;"/></p>

  </div>
</section>

<section class="slide " id="slide-16">
  <div>
    <h2>ELIZA 加強版誰都可以實作</h2>
    <ul>
<li>聊天機器人很多 <a href="https://www.chatbots.org/">https://www.chatbots.org/</a></li>
<li>真正處理「語言理解」的系統不多 (對於急需商業應用的人來說不是重點)

<ul>
<li><a href="https://pat.ai/">Language-based AI</a></li>
</ul></li>
</ul>

  </div>
</section>

<section class="slide " id="slide-17">
  <div>
    <h2>這不是我們所理解的「理解」吧？</h2>
    <p><code>YOU: My _1_ is _2_</code><br>
 <code>ELIZA: How long has your _1_ been _2_ ?</code></p>

<p><code>YOU: _1_ 覺得我很 _2_</code><br>
 <code>CELIZA: 那妳覺得妳很 _2_ 嗎？</code></p>

  </div>
</section>

<section class="slide " id="slide-18">
  <div>
    <h2>資料夠大，即便神經網路模式也不一定穩定</h2>
    <p><img src="assets/img/pttchat.png" alt="Drawing" style="width: 800px;"/></p>

  </div>
</section>

<section class="slide " id="slide-19">
  <div>
    <h2>AI, Neural Network (aka Deep Learning)</h2>
    <p><img src="assets/img/zoo.jpg" alt="Drawing" style="width: 850px;"/></p>

  </div>
</section>

<section class="slide " id="slide-20">
  <div>
    <h2>(End-to-End) AI 實作快變成中學生的課外活動</h2>
    <p><img src="assets/img/dl.png" alt="Drawing" style="width: 450px;"/>
<a href="http://playground.tensorflow.org/">Tensorflow playground</a></p>

  </div>
</section>

<section class="slide " id="slide-21">
  <div>
    <h2>Keras: Deep Learning library in R or Python within 30 seconds</h2>
    
  </div>
</section>

<section class="slide " id="slide-22">
  <div>
    <h2>但，我們應該假定這才是理解能力嗎</h2>
    <ul>
<li><strong>natural language processing</strong> to enable it to communicate successfully;</li>
<li><strong>knowledge representation</strong> to store what it knows or hears;</li>
<li><strong>automated reasoning</strong> to use the stored information to answer questions and to draw new conclusions;</li>
<li><strong>machine learning</strong> to adapt to new circumstances and to detect and extrapolate patterns.</li>
</ul>

  </div>
</section>

<section class="slide " id="slide-23">
  <div>
    <h2>題外話</h2>
    <p>測試一下班上有沒有機器人:)</p>

<blockquote>
<p>蜘蛛為何是白色的？
水手的工作？</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-24">
  <div>
    <h2>Deep Learning: a hype or go-to algorithm?</h2>
    <ul>
<li><a href="https://www.quora.com/What-are-the-main-criticism-and-limitations-of-deep-learning">main criticism</a></li>
<li><a href="https://blog.keras.io/the-limitations-of-deep-learning.html">concerns</a></li>
</ul>

  </div>
</section>

<section class="slide " id="slide-25">
  <div>
    <h2>Issues</h2>
    <ul>
<li>不是每個領域都有可得的大數據 (big data)。</li>
<li>不是每個問題都有標準答案 (labeled data)。</li>
<li>理解活動可能不是單純的模型或是序列匹配 (pattern matching/seq2seq chatbot)</li>
<li>AI 中的科學與工程 Science v.s./with Engineering?</li>
</ul>

<p><a href="https://www.quora.com/What-are-the-main-criticism-and-limitations-of-deep-learning"></a></p>

  </div>
</section>

<section class="slide " id="slide-26">
  <div>
    <h2>Last miles of the way ?</h2>
    <ul>
<li>Language understanding (vs. comprehension) and Linguistic complexity</li>
</ul>

<blockquote>
<p>&quot;human language is one of the most complex processes to be found anywhere on our planet&quot; (Tomasello, 2008).</p>

<p>Natural language understanding is sometimes referred to as an AI-complete or AI-hard problem, implying that the difficulty of these computational problems is equivalent to solving the central artificial intelligence problem. </p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-27">
  <div>
    <h2>[哲學思考] 丟一個問題給你，請想久一點</h2>
    <p>如果有機器通過了圖林測試，它還是機器嗎？
<img src="assets/img/turing_test.jpg" alt="Drawing" style="width: 400px;"/></p>

<!--念哲學系的題目-->

<blockquote>
<p>Loebner Prize Competition in Artificial Intelligence</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-28">
  <div>
    <h2>Talking to itself/themselves (娛樂效果之外的反思.....)</h2>
    <iframe width="620" height="390" src="https://www.youtube.com/embed/WnzlbyTZsQY" frameborder="0" allowfullscreen></iframe>

  </div>
</section>

<section class="slide " id="slide-29">
  <div>
    <h2>Outline</h2>
    <ol class = "build incremental">
<li>AI, Deep Learning, and the (unknown) Future</li>
<li><strong>Cognition, Computation, Linguistics and AI : a (mis)match in Heaven?</strong></li>
<li>Semantic Network: Representation, Memory and Processing</li>
<li>AI, AAI and AW (Artificial Wisdom)?</li>
</ol>

  </div>
</section>

<section class="slide shout" id="warning">
  <div>
    <h2>識</h2>
    <p><img src="assets/img/shi.png" alt="Drawing" style="width: 850px;"/></p>

  </div>
</section>

<section class="slide " id="slide-31">
  <div>
    <h2>人的歷程</h2>
    <blockquote>
<p>認識、知識、常識、意識、心識</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-32">
  <div>
    <h2>人的語言</h2>
    
  </div>
</section>

<section class="slide " id="slide-33">
  <div>
    <h2>What is Linguistics?</h2>
    <ul>
<li><strong>目的</strong>：語言學要回答語言的習得與發展,結構與功能,神經與心理機制,社會變異與演化過程等。</li>
<li><strong>應用</strong>： (大數據中的) 語言數據(語料)蘊含了文化歷史記憶,社會心理趨勢,政治輿情傾向,情緒偏好分佈,人格特質與決策行為,疾病前期徵兆等等。</li>
</ul>

<p>順便澄清一個觀念：</p>

<blockquote>
<p>Asking a linguist how many languages they speak is like asking a doctor how many diseases they have (Lynne Murphy). </p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-34">
  <div>
    <h2>What is NLP?</h2>
    <p>經驗/計算語言學 (empirical/computational linguistics) [a.k.a. Natural Language Processing] 用電腦來幫助我們回答上述問題，並產生應用。</p>

<ul>
<li>Natural Language Processing (NLP)} is a field of computer science and linguistics concerned with the interactions between computers and human (natural) languages. It began as a branch of artificial intelligence, as a very attractive methodology of human–computer interaction. </li>
</ul>

  </div>
</section>

<section class="slide " id="slide-35">
  <div>
    <h2>語言複雜度的處理</h2>
    <ul>
<li>表徵與標記 (representation and annotation)</li>
<li>計算與學習 (modeling and machine learning)</li>
<li>模擬 (simulation)</li>
</ul>

<p>以<code>計算詞彙語意學</code> (computational lexical semantics) 為例, 參考 2014 講義 <a href="https://db.tt/BzvIqk7e">ai-lecture2014.pdf</a></p>

  </div>
</section>

<section class="slide " id="slide-36">
  <div>
    <h2>語言表徵與理解</h2>
    <h3>Semantic memory and categorization</h3>

<ul>
<li><strong>Semantic memory</strong>:  our organized knowledge about the world.</li>
<li><strong>Concepts and Categories</strong>: 

<ul>
<li>The feature approach</li>
<li>The prototype approach</li>
<li>The exemplar approach (your previous experience lumped together into a category)</li>
<li>The network models</li>
</ul></li>
</ul>

<blockquote>
<p>定義遊戲練習</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-37">
  <div>
    <h2>Semantic memory</h2>
    <ul>
<li>general (common-sense) knowledge</li>
<li>linguistic knowledge</li>
<li>conceptual knowledge

<ul>
<li>Psychologists use the term concept to refer to your <strong>mental representations</strong> of a category (Murphy, 2010; Rips et al., 2012; Wisniewski, 2002). </li>
</ul></li>
</ul>

<blockquote>
<p>Cognitive scientists have found it useful to draw a distinction between <em>declarative</em> (factual) knowledge and <em>procedural</em> knowledge.</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-38">
  <div>
    <h2>「知識救援」的個人看法</h2>
    <ul>
<li>Human annotation/involvement <em>driven</em></li>
<li>Language and Knowwledge Resource <em>embedded</em></li>
</ul>

  </div>
</section>

<section class="slide " id="slide-39">
  <div>
    <h2>Machine Learning w/o Knowledge Representation and Annotation</h2>
    <ul>
<li>爭辯熱度最高的主題

<ul>
<li>標記（特徵工程）很貴、費工、太主觀</li>
<li>標記（就算沒用）反映了科學的努力與限制；至少<code>我們</code>知道<code>他們</code>在幹什麼</li>
</ul></li>
</ul>

  </div>
</section>

<section class="slide " id="slide-40">
  <div>
    <h2>More on Levels of Annotation</h2>
    <p>Units (crossing the sentence boundary) reflect the communicative function of the sentence</p>

<ul>
<li>Topic-focus articulation/rhetorical structures and discourse connectives/anaphora and coreference </li>
</ul>

  </div>
</section>

<section class="slide " id="slide-41">
  <div>
    <h2>Topic-Focus Articulation (TFA)</h2>
    <ul>
<li><strong>Topic</strong>: <code>What is the sentence about?</code>

<ul>
<li>The topic (or theme) is the part of the proposition that is being talked about (predicated). Once stated, the topic is therefore <em>old news</em>, i.e. the things already mentioned and understood. </li>
</ul></li>
<li><strong>Focus</strong>: <code>What information about the topic is asserted?</code> 

<ul>
<li>The focus determines which part of the sentence contributes the most important information. The focus may be highlighted either prosodically or syntactically or both, depending on the language.</li>
</ul></li>
<li>An important role is played by the position of the intonation marker.</li>
</ul>

  </div>
</section>

<section class="slide " id="slide-42">
  <div>
    <h2>Deep (Linguistic) Learning: batteries included?</h2>
    <p>But, which Semantics?</p>

<ul>
<li>Lexical Semantics</li>
<li>Neural Semantics</li>
<li>Vector Semantics</li>
</ul>

  </div>
</section>

<section class="slide " id="slide-43">
  <div>
    <h2>Network Representation of Semantics</h2>
    <iframe width="520" height="415" src="assets/widgets/nn.html" frameborder="0" allowfullscreen></iframe>

  </div>
</section>

<section class="slide " id="slide-44">
  <div>
    <h2>Network Analysis</h2>
    <p><code>micro motifs and macro behavior</code></p>

<ul>
<li>focuses on (in)dependent actors at the <code>micro level</code> and the consequences of their behavior at the <code>macro level</code>.</li>
<li><em>ideographic</em> approach stresses the uniqueness of a phenomenon; <em>nomothetic</em> approach stresses law-likeness.</li>
</ul>

  </div>
</section>

<section class="slide " id="slide-45">
  <div>
    <h2><strong>Small worlds</strong>:</h2>
    <p>&#39;six degrees of separation&#39; (Watts and Strogatz, 1998)</p>

<pre><code class="r">sw &lt;- sample_smallworld(dim=2, size=10, nei=1, p=0.1)
plot(sw, vertex.size=6, vertex.label=NA, layout=layout_in_circle)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-2-1.png" alt="plot of chunk unnamed-chunk-2"></p>

  </div>
</section>

<section class="slide " id="slide-46">
  <div>
    <h2>Lexical network (<a href=""><code>Wordnet</code></a>)</h2>
    <p><img src="assets/img/cwn.png" alt="Drawing" style="width: 400px;"/></p>

  </div>
</section>

<section class="slide " id="slide-47">
  <div>
    <h2>Chinese Wordnet</h2>
    <ul>
<li>A network representation of lexical semantic knowledge in Chinese.</li>
<li>Toward an OntoLex resource for Natural Language Processing.</li>
</ul>

  </div>
</section>

<section class="slide " id="slide-48">
  <div>
    <h2>Vector Semantics</h2>
    <ul>
<li>Like the <strong>neural language models</strong>, the <code>word2vec</code> models learn embeddings by training
a network to predict neighboring words.</li>
</ul>

  </div>
</section>

<section class="slide " id="slide-49">
  <div>
    <h2>Vector Semantics</h2>
    <p>Word Embeddings</p>

<!--
<iframe width="800" height="515" src="http://140.112.147.121:8288" frameborder="0" allowfullscreen></iframe>  -->

<!-- <img src="images/embeddings.png" alt="Drawing" style="width: 400px;"/> -->

  </div>
</section>

<section class="slide " id="slide-50">
  <div>
    <h2>Neural Semantic Network</h2>
    <p><code>Gallant lab Brain Viewer</code></p>

  </div>
</section>

<section class="slide " id="slide-51">
  <div>
    <h2>Neural Semantic Network</h2>
    
  </div>
</section>

<section class="slide " id="slide-52">
  <div>
    <h2>Human Connectome Project (HCP)</h2>
    <blockquote>
<p>a <a href="https://www.humanconnectome.org/">consortium</a> whose goal is to map “human brain circuitry in a target number of 1200 healthy adults using cutting-edge methods of noninvasive neuroimaging” </p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-53">
  <div>
    <h2>Neural WordNet</h2>
    <ul>
<li>Neurologically-based Ontology and Semantic Space (Huth et al. 2012; Huth et al. 2016, Nature
) Brain altas: same with Chinese?</li>
</ul>

<p><img style="float:middle" src="assets/img/polya.jpg" />
<img align="middle" src="assets/img/polya.jpg" /></p>

<p><img src="assets/img/ontolex_wn.png" alt="Drawing" style="width: 500px;"/>
<a href="https://www.youtube.com/watch?v=0FDtsbLZBuM">https://www.youtube.com/watch?v=0FDtsbLZBuM</a> </p>

  </div>
</section>

<section class="slide " id="slide-54">
  <div>
    <h2><strong>(Words/Chunks?) on the Brain: A Semantic Map of the Cortex</strong></h2>
    <p>DeepMind 的 leader 要跟神經科學學習 / Hinton 認為 back-propagation 要打掉重練</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/k61nJkx5aDQ" frameborder="0" allowfullscreen></iframe>

  </div>
</section>

<section class="slide " id="slide-55">
  <div>
    <h2>Chinese QIEs</h2>
    <ul>
<li>Is Construction Grammar Neuroscientifically Plausible? </li>
</ul>

<!--
![plot of chunk unnamed-chunk-3](assets/fig/unnamed-chunk-3-1.png)
-->

  </div>
</section>

<section class="slide " id="slide-56">
  <div>
    <h2>Chinese QIEs</h2>
    <pre><code class="r">#orthographic(img)
</code></pre>

  </div>
</section>

<section class="slide " id="slide-57">
  <div>
    <h2>Chinese QIEs</h2>
    <ul>
<li>Idiom, Near, Far conditions were contrasted against random condition. </li>
<li>BOLD signal increase:

<ul>
<li>Idiom condition: left and right AG (angular gyrus), PCC (posterior cingulate cortex)</li>
<li>Near conditions at left AG and IFG (left Inferior frontal gyrus )</li>
<li>No significant difference found in Far vs. Random condition.</li>
</ul></li>
</ul>

<p><img src="assets/img/qie.fmri.png" class="one-col-image"></p>

  </div>
</section>

<section class="slide " id="slide-58">
  <div>
    <h2>結論，有嗎之一</h2>
    <h2>AI needs greater representation from the humanities</h2>

<ul>
<li>人的問題涉及行為、經驗、心靈、意識、生理變化等。</li>
<li>語言裡反映了慾望、記憶與遺忘、錯誤、情緒、愛、性格。</li>
</ul>

<blockquote>
<p>人格面具,自我實現、善心、惻隱之心、同情心、助人、愛心、民主、創造、
    幽默、風趣、詼諧、恐懼、自卑、氣質、非理性決策（直覺</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-59">
  <div>
    <h2>再確認：妳是人嗎</h2>
    <p>下面這句話一秒鐘看完並說出意思</p>

<blockquote>
<p>[賣女孩的小火柴][請上獎領台]</p>
</blockquote>

  </div>
</section>

<section class="slide " id="slide-60">
  <div>
    <h2>結論，有嗎之二</h2>
    <p><img src="assets/img/ai.linguistics.png" alt="Drawing" style="width: 750px;"/></p>

  </div>
</section>

<section class="slide " id="slide-61">
  <div>
    <h2>Reference</h2>
    <p>[1] Huth AG, de Heer WA, Griffiths TL, Theunissen FE, &amp; Gallant JL (2016). Natural speech reveals the semantic maps that tile human cerebral cortex. Nature, 532 (7600), 453-8 PMID: 27121839</p>

<p>[2] Friedemann Pulvermüller, Bert Cappelle and Yury Shtyrov. (2013). Brain basis of meaning, words, constructions, and grammar. In: Graeme Trousdale and Thomas Hoffmann (eds.), Oxford Handbook of Construction Grammar. Oxford: Oxford University Press, 397-416. </p>

  </div>
</section>

  <div class="progress">
    <div></div>
  </div>
	<script src="libraries/frameworks/shower/shower.js"></script>
	
	<script src="shared/shiny.js" type="text/javascript"></script>
	<script src="shared/slider/js/jquery.slider.min.js"></script>
	<script src="shared/bootstrap/js/bootstrap.min.js"></script>
	<link rel="stylesheet" href="shared/slider/css/jquery.slider.min.css"></link>
	
	<!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
	    tex2jax: {
	      inlineMath: [['$','$'], ['\\(','\\)']],
	      processEscapes: true
	    }
	  });
	</script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	<!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script> -->
	<script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
	<script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>
	<!-- DONE LOADING HIGHLIGHTER JS FILES -->
	 
		<!-- Copyright © 2010–2012 Vadim Makeev — pepelsbey.net -->
	<!-- Photos by John Carey — fiftyfootshadows.net -->
</body>
</html>